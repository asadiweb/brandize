import os
import json
import feedparser
import requests
from bs4 import BeautifulSoup
from googleapiclient.discovery import build
from google.oauth2 import service_account
from deep_translator import GoogleTranslator
import datetime
import base64

# --- ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù…Ø­ÛŒØ·ÛŒ ---
BLOG_ID = os.getenv("BLOG_ID")
FEED_URL = os.getenv("FEED_URL")
IMG_PREFIX = os.getenv("IMG_PREFIX", "")
POSTED_FILE = os.getenv("POSTED_FILE", "posted_titles.json")
GOOGLE_CREDENTIALS = os.getenv("GOOGLE_CREDENTIALS")  # Ú©Ù„ÛŒØ¯ Ø³Ø±ÙˆÛŒØ³ Ø§Ø² GitHub Secrets
GITHUB_TOKEN = os.getenv("MY_GITHUB_TOKEN")
GITHUB_REPO = os.getenv("MY_GITHUB_REPO")

# --- Ù…Ø¯ÛŒØ±ÛŒØª ÙØ§ÛŒÙ„ Ø¹Ù†Ø§ÙˆÛŒÙ† Ù…Ù†ØªØ´Ø± Ø´Ø¯Ù‡ ---
def load_posted_titles():
    if not os.path.exists(POSTED_FILE):
        return {}
    try:
        with open(POSTED_FILE, "r", encoding="utf-8") as f:
            content = f.read().strip()
            if not content:
                return {}
            return json.loads(content)
    except Exception as e:
        print(f"âš ï¸ Ø®Ø·Ø§ Ø¯Ø± Ø®ÙˆØ§Ù†Ø¯Ù† {POSTED_FILE}: {e}")
        return {}

def save_posted_titles(data):
    try:
        with open(POSTED_FILE, "w", encoding="utf-8") as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
    except Exception as e:
        print(f"âš ï¸ Ø®Ø·Ø§ Ø¯Ø± Ø°Ø®ÛŒØ±Ù‡ {POSTED_FILE}: {e}")

# --- Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Blogger API ---
def get_blogger_service():
    if not GOOGLE_CREDENTIALS:
        raise RuntimeError("âŒ GOOGLE_CREDENTIALS Ø¯Ø± Ù…Ø­ÛŒØ· ØªØ¹Ø±ÛŒÙ Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª")
    info = json.loads(GOOGLE_CREDENTIALS)
    creds = service_account.Credentials.from_service_account_info(
        info, scopes=["https://www.googleapis.com/auth/blogger"]
    )
    return build("blogger", "v3", credentials=creds)

# --- ØªØ±Ø¬Ù…Ù‡ Ù…ØªÙ† ---
def translate_text(text, target="fa"):
    try:
        return GoogleTranslator(source="auto", target=target).translate(text)
    except Exception as e:
        print(f"âš ï¸ Ø®Ø·Ø§ Ø¯Ø± ØªØ±Ø¬Ù…Ù‡: {e}")
        return text

# --- Ø¯Ø§Ù†Ù„ÙˆØ¯ Ùˆ Ø¢Ù¾Ù„ÙˆØ¯ ØªØµÙˆÛŒØ± (ÙØ¹Ù„Ø§Ù‹ Ù‡Ù…Ø§Ù† URL Ø¨Ø±Ú¯Ø´Øª Ø¯Ø§Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯) ---
def download_and_rehost_image(url, title, idx):
    try:
        resp = requests.get(url, timeout=15)
        if resp.status_code != 200:
            return url
        # Ø§Ú¯Ø± Ù…ÛŒØ®ÙˆØ§ÛŒ ØªØµÙˆÛŒØ± Ø±ÙˆÛŒ GitHub Ø¢Ù¾Ù„ÙˆØ¯ Ø¨Ø´Ù‡ØŒ Ø§ÛŒÙ†Ø¬Ø§ Ø§Ø¶Ø§ÙÙ‡ Ú©Ù†
        ext = url.split(".")[-1].split("?")[0]
        timestamp = datetime.datetime.now().strftime("%Y%m%d%H%M%S")
        filename = f"{title[:20].replace(' ','_')}_{idx}_{timestamp}.{ext}"
        path_in_repo = f"images/{filename}"

        api_url = f"https://api.github.com/repos/{GITHUB_REPO}/contents/{path_in_repo}"
        headers = {"Authorization": f"token {GITHUB_TOKEN}"}
        data = {"message": f"upload {filename}",
                "content": base64.b64encode(resp.content).decode("utf-8")}

        r = requests.put(api_url, headers=headers, json=data)
        if r.status_code in [200, 201]:
            print(f"âœ… Ø¹Ú©Ø³ Ø¢Ù¾Ù„ÙˆØ¯ Ø´Ø¯: {filename}")
            return f"{IMG_PREFIX}/{filename}" if IMG_PREFIX else f"{filename}"
        else:
            print(f"âš ï¸ Ø¢Ù¾Ù„ÙˆØ¯ Ø¹Ú©Ø³ {filename} Ù…ÙˆÙÙ‚ Ù†Ø¨ÙˆØ¯: {r.text}")
            return url
    except Exception as e:
        print(f"âš ï¸ Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª ØªØµÙˆÛŒØ± {url}: {e}")
        return url

# --- Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù…Ø­ØªÙˆØ§ ---
def process_content(entry):
    content_de = getattr(entry, "summary", getattr(entry, "description", ""))
    soup = BeautifulSoup(content_de, "html.parser")

    # Ø§ØµÙ„Ø§Ø­ Ù„ÛŒÙ†Ú© ØªØµØ§ÙˆÛŒØ±
    for idx, img in enumerate(soup.find_all("img")):
        src = img.get("src")
        if src:
            img["src"] = download_and_rehost_image(src, entry.title, idx)

    # Ù¾Ø§Ú© Ú©Ø±Ø¯Ù† Ù„ÛŒÙ†Ú©â€ŒÙ‡Ø§
    for a in soup.find_all("a"):
        a.unwrap()

    return str(soup)

# --- Ø§Ù†ØªØ´Ø§Ø± Ù¾Ø³Øª Ø¯Ø± Ø¨Ù„Ø§Ú¯Ø± ---
def post_to_blogger(service, title, content):
    body = {
        "kind": "blogger#post",
        "title": title,
        "content": content
    }
    try:
        post = service.posts().insert(blogId=BLOG_ID, body=body, isDraft=True).execute()
        print(f"âœ… Ù¾Ø³Øª Ù¾ÛŒØ´â€ŒÙ†ÙˆÛŒØ³ Ø§ÛŒØ¬Ø§Ø¯ Ø´Ø¯: {post['url']}")
        return post
    except Exception as e:
        print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø§Ù†ØªØ´Ø§Ø± Ù¾Ø³Øª: {e}")
        return None

# --- Ø§Ø¬Ø±Ø§ÛŒ Ø§ØµÙ„ÛŒ ---
def main():
    print("ğŸš€ Ø´Ø±ÙˆØ¹ Ø§Ø¬Ø±Ø§ÛŒ Ø§Ø³Ú©Ø±ÛŒÙ¾Øª Ø¨Ù„Ø§Ú¯Ø±")
    posted_titles = load_posted_titles()
    feed = feedparser.parse(FEED_URL)
    if not feed.entries:
        print("âš ï¸ Ù‡ÛŒÚ† Ù…Ø·Ù„Ø¨ÛŒ Ø¯Ø± ÙÛŒØ¯ Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯")
        return

    service = get_blogger_service()

    for entry in feed.entries[:5]:  # ÙÙ‚Ø· Ûµ Ù¾Ø³Øª Ø¢Ø®Ø±
        translated_title = translate_text(entry.title, "fa")
        if translated_title in posted_titles:
            print(f"â© Ù‚Ø¨Ù„Ø§Ù‹ Ù…Ù†ØªØ´Ø± Ø´Ø¯Ù‡: {translated_title}")
            continue

        content = process_content(entry)
        post_to_blogger(service, translated_title, content)
        posted_titles[translated_title] = True
        save_posted_titles(posted_titles)

    print("ğŸ Ù¾Ø§ÛŒØ§Ù† Ø§Ø¬Ø±Ø§ÛŒ Ø§Ø³Ú©Ø±ÛŒÙ¾Øª")

if __name__ == "__main__":
    try:
        main()
    except Exception as e:
        print(f"âŒ Ø®Ø·Ø§ÛŒ ØºÛŒØ±Ù…Ù†ØªØ¸Ø±Ù‡: {e}")
        exit(1)
