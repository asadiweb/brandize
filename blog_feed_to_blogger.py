import os
import json
import feedparser
import requests
from bs4 import BeautifulSoup
from googleapiclient.discovery import build
from google.oauth2 import service_account
from deep_translator import GoogleTranslator
import datetime
import base64

# --- ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù…Ø­ÛŒØ·ÛŒ ---
BLOG_ID = os.getenv("BLOG_ID")
FEED_URL = os.getenv("FEED_URL")
IMG_PREFIX = os.getenv("IMG_PREFIX", "")
POSTED_FILE = os.getenv("POSTED_FILE", "posted_titles.json")
SERVICE_ACCOUNT_FILE = os.getenv("SERVICE_ACCOUNT_FILE", "service_account.json")
GOOGLE_CREDENTIALS = os.getenv("GOOGLE_CREDENTIALS")  # Ø§Ø² GitHub Secrets

# --- Ù…Ø¯ÛŒØ±ÛŒØª ÙØ§ÛŒÙ„ Ø¹Ù†Ø§ÙˆÛŒÙ† Ù…Ù†ØªØ´Ø± Ø´Ø¯Ù‡ ---
def load_posted_titles():
    if not os.path.exists(POSTED_FILE):
        return {}
    try:
        with open(POSTED_FILE, "r", encoding="utf-8") as f:
            content = f.read().strip()
            if not content:
                return {}
            return json.loads(content)
    except Exception as e:
        print(f"âš ï¸ Ø®Ø·Ø§ Ø¯Ø± Ø®ÙˆØ§Ù†Ø¯Ù† {POSTED_FILE}: {e}")
        return {}

def save_posted_titles(data):
    try:
        with open(POSTED_FILE, "w", encoding="utf-8") as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
    except Exception as e:
        print(f"âš ï¸ Ø®Ø·Ø§ Ø¯Ø± Ø°Ø®ÛŒØ±Ù‡ {POSTED_FILE}: {e}")

# --- Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Blogger API ---
def get_blogger_service():
    if GOOGLE_CREDENTIALS:
        info = json.loads(GOOGLE_CREDENTIALS)
        creds = service_account.Credentials.from_service_account_info(
            info, scopes=["https://www.googleapis.com/auth/blogger"]
        )
        print("âœ… Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² GOOGLE_CREDENTIALS")
    elif os.path.exists(SERVICE_ACCOUNT_FILE):
        creds = service_account.Credentials.from_service_account_file(
            SERVICE_ACCOUNT_FILE, scopes=["https://www.googleapis.com/auth/blogger"]
        )
        print(f"âœ… Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² ÙØ§ÛŒÙ„ Ø³Ø±ÙˆÛŒØ³: {SERVICE_ACCOUNT_FILE}")
    else:
        raise RuntimeError("âŒ Ù‡ÛŒÚ† Ú©Ù„ÛŒØ¯ Ø³Ø±ÙˆÛŒØ³ Google Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯")
    return build("blogger", "v3", credentials=creds)

# --- ØªØ±Ø¬Ù…Ù‡ Ù…ØªÙ† ---
def translate_text(text, target="fa"):
    try:
        return GoogleTranslator(source="auto", target=target).translate(text)
    except Exception as e:
        print(f"âš ï¸ Ø®Ø·Ø§ Ø¯Ø± ØªØ±Ø¬Ù…Ù‡: {e}")
        return text

# --- Ù¾Ø§Ú© Ú©Ø±Ø¯Ù† Ù„ÛŒÙ†Ú©â€ŒÙ‡Ø§ ---
def clean_links(html_content):
    soup = BeautifulSoup(html_content, "html.parser")
    for a in soup.find_all("a"):
        a.unwrap()
    return str(soup)

# --- Ø¯Ø§Ù†Ù„ÙˆØ¯ Ùˆ Ø¢Ù¾Ù„ÙˆØ¯ ØªØµÙˆÛŒØ± ---
def download_and_rehost_image(url, title="", idx=0):
    try:
        resp = requests.get(url, timeout=15)
        if resp.status_code != 200:
            print(f"âš ï¸ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø¹Ú©Ø³ {url} Ù…ÙˆÙÙ‚ Ù†Ø¨ÙˆØ¯")
            return url
        # filename Ùˆ path Ù…ÛŒâ€ŒØªÙˆØ§Ù† Ø¨Ø±Ø§ÛŒ Ø¢Ù¾Ù„ÙˆØ¯ Ø¨Ù‡ GitHub ÛŒØ§ CDN Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø´ÙˆØ¯
        ext = url.split(".")[-1].split("?")[0]
        timestamp = datetime.datetime.now().strftime("%Y%m%d%H%M%S")
        filename = f"{title[:20].replace(' ','_')}_{idx}_{timestamp}.{ext}"
        # ÙØ¹Ù„Ø§Ù‹ Ù‡Ù…Ø§Ù† URL Ø§ØµÙ„ÛŒ Ø¨Ø±Ú¯Ø±Ø¯Ø§Ù†Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯
        return IMG_PREFIX + url if IMG_PREFIX else url
    except Exception as e:
        print(f"âš ï¸ Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª ØªØµÙˆÛŒØ± {url}: {e}")
        return url

# --- Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù…Ø­ØªÙˆØ§ ---
def process_content(entry):
    content_html = entry.summary if "summary" in entry else entry.description
    content_html = clean_links(content_html)
    soup = BeautifulSoup(content_html, "html.parser")
    for idx, img in enumerate(soup.find_all("img")):
        src = img.get("src")
        if src:
            img["src"] = download_and_rehost_image(src, entry.title, idx)
    return str(soup)

# --- Ø§Ù†ØªØ´Ø§Ø± Ù¾Ø³Øª Ø¯Ø± Ø¨Ù„Ø§Ú¯Ø± ---
def post_to_blogger(service, title, content, draft=True):
    body = {
        "kind": "blogger#post",
        "blog": {"id": BLOG_ID},
        "title": title,
        "content": content
    }
    try:
        post = service.posts().insert(blogId=BLOG_ID, body=body, isDraft=draft).execute()
        print(f"âœ… Ù¾Ø³Øª {'Ù¾ÛŒØ´â€ŒÙ†ÙˆÛŒØ³' if draft else 'Ù…Ù†ØªØ´Ø± Ø´Ø¯Ù‡'} Ø§ÛŒØ¬Ø§Ø¯ Ø´Ø¯: {post['url']}")
        return post
    except Exception as e:
        print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø§Ù†ØªØ´Ø§Ø± Ù¾Ø³Øª: {e}")
        return None

# --- Ø§Ø¬Ø±Ø§ÛŒ Ø§ØµÙ„ÛŒ ---
def main():
    try:
        print("ğŸš€ Ø´Ø±ÙˆØ¹ Ø§Ø¬Ø±Ø§ÛŒ Ø§Ø³Ú©Ø±ÛŒÙ¾Øª Ø¨Ù„Ø§Ú¯Ø±")
        posted_titles = load_posted_titles()
        feed = feedparser.parse(FEED_URL)
        if not feed.entries:
            print("âš ï¸ Ù‡ÛŒÚ† Ù…Ø·Ù„Ø¨ÛŒ Ø¯Ø± ÙÛŒØ¯ Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯")
            return

        service = get_blogger_service()

        for entry in feed.entries[:5]:  # ÙÙ‚Ø· Ûµ Ù¾Ø³Øª Ø¢Ø®Ø±
            translated_title = translate_text(entry.title, "fa")
            if translated_title in posted_titles:
                print(f"â© Ù‚Ø¨Ù„Ø§Ù‹ Ù…Ù†ØªØ´Ø± Ø´Ø¯Ù‡: {translated_title}")
                continue

            content = process_content(entry)
            post = post_to_blogger(service, translated_title, content, draft=True)
            if post:
                posted_titles[translated_title] = post["url"]
                save_posted_titles(posted_titles)

        print("ğŸ Ù¾Ø§ÛŒØ§Ù† Ø§Ø¬Ø±Ø§ÛŒ Ø§Ø³Ú©Ø±ÛŒÙ¾Øª")

    except Exception as e:
        print(f"âŒ Ø®Ø·Ø§ÛŒ ØºÛŒØ±Ù…Ù†ØªØ¸Ø±Ù‡: {e}")

if __name__ == "__main__":
    main()
