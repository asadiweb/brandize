import os
import json
import feedparser
import requests
from bs4 import BeautifulSoup
from googleapiclient.discovery import build
from google.oauth2 import service_account
from deep_translator import GoogleTranslator
import base64
import datetime

# --- ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù…Ø­ÛŒØ·ÛŒ ---
BLOG_ID = os.getenv("BLOG_ID")
FEED_URL = os.getenv("FEED_URL")
IMG_PREFIX = os.getenv("IMG_PREFIX", "")
POSTED_FILE = os.getenv("POSTED_FILE", "posted_titles.json")
GITHUB_TOKEN = os.getenv("MY_GITHUB_TOKEN")
GITHUB_REPO = os.getenv("MY_GITHUB_REPO")
GOOGLE_CREDENTIALS = os.getenv("GOOGLE_CREDENTIALS")  # Ú©Ù„ÛŒØ¯ Ø³Ø±ÙˆÛŒØ³ Ø§Ø² GitHub Secrets
MAX_POSTS = int(os.getenv("MAX_POSTS", 5))  # ØªØ¹Ø¯Ø§Ø¯ Ù¾Ø³Øªâ€ŒÙ‡Ø§ÛŒ Ù‚Ø§Ø¨Ù„ Ù¾Ø±Ø¯Ø§Ø²Ø´

# --- Ù…Ø¯ÛŒØ±ÛŒØª ÙØ§ÛŒÙ„ Ø¹Ù†Ø§ÙˆÛŒÙ† Ù…Ù†ØªØ´Ø± Ø´Ø¯Ù‡ ---
def load_posted_titles():
    if not os.path.exists(POSTED_FILE):
        return {}
    try:
        with open(POSTED_FILE, "r", encoding="utf-8") as f:
            content = f.read().strip()
            if not content:
                return {}
            return json.loads(content)
    except Exception as e:
        print(f"âš ï¸ Ø®Ø·Ø§ Ø¯Ø± Ø®ÙˆØ§Ù†Ø¯Ù† {POSTED_FILE}: {e}")
        return {}

def save_posted_titles(data):
    try:
        with open(POSTED_FILE, "w", encoding="utf-8") as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
    except Exception as e:
        print(f"âš ï¸ Ø®Ø·Ø§ Ø¯Ø± Ø°Ø®ÛŒØ±Ù‡ {POSTED_FILE}: {e}")

# --- Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Blogger API ---
def get_blogger_service():
    if not GOOGLE_CREDENTIALS:
        raise RuntimeError("âŒ GOOGLE_CREDENTIALS Ø¯Ø± Ù…Ø­ÛŒØ· ØªØ¹Ø±ÛŒÙ Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª")
    info = json.loads(GOOGLE_CREDENTIALS)
    creds = service_account.Credentials.from_service_account_info(
        info, scopes=["https://www.googleapis.com/auth/blogger"]
    )
    return build("blogger", "v3", credentials=creds)

# --- ØªØ±Ø¬Ù…Ù‡ Ù…ØªÙ† ---
def translate_text(text, target="fa"):
    try:
        return GoogleTranslator(source="auto", target=target).translate(text)
    except Exception as e:
        print(f"âš ï¸ Ø®Ø·Ø§ Ø¯Ø± ØªØ±Ø¬Ù…Ù‡: {e}")
        return text

# --- Ø¯Ø§Ù†Ù„ÙˆØ¯ Ùˆ Ø¢Ù¾Ù„ÙˆØ¯ ØªØµÙˆÛŒØ± Ø±ÙˆÛŒ GitHub ---
def upload_image_to_github(img_url, title, idx):
    try:
        resp = requests.get(img_url, timeout=15)
        if resp.status_code != 200:
            print(f"âš ï¸ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø¹Ú©Ø³ {img_url} Ù…ÙˆÙÙ‚ Ù†Ø¨ÙˆØ¯")
            return img_url
    except Exception as e:
        print(f"âš ï¸ Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø¹Ú©Ø³ {img_url}: {e}")
        return img_url

    ext = img_url.split('.')[-1].split("?")[0]
    timestamp = datetime.datetime.now().strftime("%Y%m%d%H%M%S")
    filename = f"{title[:20].replace(' ','_')}_{idx}_{timestamp}.{ext}"
    path_in_repo = f"images/{filename}"

    api_url = f"https://api.github.com/repos/{GITHUB_REPO}/contents/{path_in_repo}"
    headers = {"Authorization": f"token {GITHUB_TOKEN}"}
    data = {
        "message": f"upload {filename}",
        "content": base64.b64encode(resp.content).decode("utf-8")
    }

    r = requests.put(api_url, headers=headers, json=data)
    if r.status_code in [200, 201]:
        print(f"âœ… Ø¹Ú©Ø³ Ø¢Ù¾Ù„ÙˆØ¯ Ø´Ø¯: {filename}")
        return f"{IMG_PREFIX}/{filename}"
    else:
        print(f"âš ï¸ Ø¢Ù¾Ù„ÙˆØ¯ Ø¹Ú©Ø³ {filename} Ù…ÙˆÙÙ‚ Ù†Ø¨ÙˆØ¯: {r.text}")
        return img_url

# --- Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù…Ø­ØªÙˆØ§ ---
def process_content(entry):
    soup = BeautifulSoup(entry.summary, "html.parser")
    for idx, img in enumerate(soup.find_all("img")):
        src = img.get("src")
        if src:
            new_src = upload_image_to_github(src, entry.title, idx)
            img["src"] = new_src
    return str(soup)

# --- Ø§Ù†ØªØ´Ø§Ø± Ù¾Ø³Øª Ø¯Ø± Ø¨Ù„Ø§Ú¯Ø± ---
def post_to_blogger(service, title, content, draft=True):
    body = {
        "kind": "blogger#post",
        "blog": {"id": BLOG_ID},
        "title": title,
        "content": content,
    }
    try:
        post = service.posts().insert(blogId=BLOG_ID, body=body, isDraft=draft).execute()
        status = "Ù¾ÛŒØ´â€ŒÙ†ÙˆÛŒØ³" if draft else "Ù…Ù†ØªØ´Ø± Ø´Ø¯"
        print(f"âœ… Ù¾Ø³Øª {status}: {post['url']}")
        return post
    except Exception as e:
        print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø§Ù†ØªØ´Ø§Ø± Ù¾Ø³Øª: {e}")
        return None

# --- Ø§Ø¬Ø±Ø§ÛŒ Ø§ØµÙ„ÛŒ ---
def main():
    print("ğŸš€ Ø´Ø±ÙˆØ¹ Ø§Ø¬Ø±Ø§ÛŒ Ø§Ø³Ú©Ø±ÛŒÙ¾Øª Ø¨Ù„Ø§Ú¯Ø±")
    posted_titles = load_posted_titles()
    feed = feedparser.parse(FEED_URL)
    if not feed.entries:
        print("âš ï¸ Ù‡ÛŒÚ† Ù…Ø·Ù„Ø¨ÛŒ Ø¯Ø± ÙÛŒØ¯ Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯")
        return

    service = get_blogger_service()

    for entry in feed.entries[:MAX_POSTS]:
        translated_title = translate_text(entry.title, "fa")
        if translated_title in posted_titles:
            print(f"â© Ù‚Ø¨Ù„Ø§Ù‹ Ù…Ù†ØªØ´Ø± Ø´Ø¯Ù‡: {translated_title}")
            continue

        content = process_content(entry)
        post_to_blogger(service, translated_title, content, draft=True)  # Ø§Ø±Ø³Ø§Ù„ Ø¨Ù‡ ØµÙˆØ±Øª Ù¾ÛŒØ´â€ŒÙ†ÙˆÛŒØ³
        posted_titles[translated_title] = True
        save_posted_titles(posted_titles)

    print("ğŸ Ù¾Ø§ÛŒØ§Ù† Ø§Ø¬Ø±Ø§ÛŒ Ø§Ø³Ú©Ø±ÛŒÙ¾Øª")

if __name__ == "__main__":
    try:
        main()
    except Exception as e:
        print(f"âŒ Ø®Ø·Ø§ÛŒ ØºÛŒØ±Ù…Ù†ØªØ¸Ø±Ù‡: {e}")
        exit(1)
